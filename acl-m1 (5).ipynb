{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12711806,"sourceType":"datasetVersion","datasetId":8034264}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#HOTELS.CSV \nimport numpy as np # linear algebra \nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) \nhotels = pd.read_csv(\"/kaggle/input/international-hotel-booking-analytics/hotels.csv\") \n# Step 3: View basic info \nprint(\"Shape:\", hotels.shape) \nprint(\"\\n--- Columns ---\\n\", hotels.columns) \nprint(\"\\n--- Null Values ---\\n\", hotels.isnull().sum()) \nprint(\"\\n--- Duplicate Rows:\", hotels.duplicated().sum()) \n\ncolumns_to_drop = ['lat', 'lon'] \nhotels.drop(columns=columns_to_drop, inplace=True) \nhotels.head() \n\nhotels.to_csv(\"cleaned_hotels.csv\", index=False) #The lat&lan columns have been dropped because they are unnecessary description for the hotel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:35:58.517605Z","iopub.execute_input":"2025-10-24T12:35:58.517941Z","iopub.status.idle":"2025-10-24T12:35:58.929597Z","shell.execute_reply.started":"2025-10-24T12:35:58.517916Z","shell.execute_reply":"2025-10-24T12:35:58.928552Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.DATA CLEANING\n## 1.1:Loading and Initial Cleaning of Hotels Data\n\nWe first load the `hotels.csv` dataset to inspect its structure and quality. Key steps:\n\n- Checked the **shape** to understand the number of rows and columns.\n- Listed all **column names** to see what features are available.\n- Checked for **missing values** to detect incomplete data.\n- Checked for **duplicate rows** to remove redundancy.\n\nAfter inspection, we dropped the `lat` and `lon` columns because they are not needed for predictive modeling in this project â€” the exact geographic coordinates are not informative for country group predictions.\n\nFinally, the cleaned dataset is saved as `cleaned_hotels.csv` for further analysis.\n","metadata":{}},{"cell_type":"code","source":"#REVIEWS.CSV\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nreviews = pd.read_csv('/kaggle/input/international-hotel-booking-analytics/reviews.csv')\nprint(\"Shape:\", reviews.shape)\nprint(\"\\n--- Columns ---\\n\", reviews.columns)\nprint(\"\\n--- Null Values ---\\n\", reviews.isnull().sum())\nprint(\"\\n--- Duplicate Rows:\", reviews.duplicated().sum())\n\nreviews.head()\n\nreviews.to_csv(\"cleaned_reviews.csv\", index=False)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:35:58.931118Z","iopub.execute_input":"2025-10-24T12:35:58.931390Z","iopub.status.idle":"2025-10-24T12:35:59.861030Z","shell.execute_reply.started":"2025-10-24T12:35:58.931369Z","shell.execute_reply":"2025-10-24T12:35:59.859683Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.2 :Loading and Initial Cleaning of Reviews Data\n\nWe load the `reviews.csv` dataset to inspect its structure and quality. Key steps:\n\n- Checked the **shape** to understand the number of rows and columns.\n- Listed all **column names** to see the types of review features available.\n- Checked for **missing values** to identify incomplete reviews.\n- Checked for **duplicate rows** to remove redundant entries.\n\nAfter inspection, the cleaned dataset is saved as `cleaned_reviews.csv` for further analysis. At this stage, no columns are dropped because all review features may be relevant for the predictive modeling task.\n\n","metadata":{}},{"cell_type":"code","source":"#USERS.CSV\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nusers = pd.read_csv('/kaggle/input/international-hotel-booking-analytics/users.csv')\nprint(\"Shape:\", users.shape)\nprint(\"\\n--- Columns ---\\n\", users.columns)\nprint(\"\\n--- Null Values ---\\n\", users.isnull().sum())\nprint(\"\\n--- Duplicate Rows:\", users.duplicated().sum())\n\ncolumns_to_drop = ['country','join_date'] \nusers.drop(columns=columns_to_drop, inplace=True)\n\nusers.head()\n\nusers.to_csv(\"cleaned_users.csv\", index=False)\n\n\n\n#The country&join_date columns have been dropped because they are unnecessary description for the users review on the hotel.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:35:59.862258Z","iopub.execute_input":"2025-10-24T12:35:59.864459Z","iopub.status.idle":"2025-10-24T12:35:59.901668Z","shell.execute_reply.started":"2025-10-24T12:35:59.864417Z","shell.execute_reply":"2025-10-24T12:35:59.900264Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.3: Loading and Initial Cleaning of Users Data\n\nWe load the `users.csv` dataset to inspect the user information. Key steps:\n\n- Checked the **shape** to see the number of users and available features.\n- Listed all **columns** to understand user attributes.\n- Checked for **missing values** and **duplicate rows** to ensure data quality.\n- Dropped unnecessary columns:\n  - `country`: This column is redundant because the target variable `country_group` already encodes the userâ€™s location in groups.\n  - `join_date`: This timestamp is not relevant to predicting user behavior or hotel ratings, and including it could introduce noise.\n\nBy removing irrelevant columns, we simplify the dataset, reduce dimensionality, and avoid including features that do not contribute to our predictive modeling task.\n\nThe cleaned dataset is saved as `cleaned_users.csv` for merging with hotel and review data in later steps.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nhotels = pd.read_csv(\"cleaned_hotels.csv\") # Provided city information for each hotel_id.\nreviews = pd.read_csv(\"cleaned_reviews.csv\")#Provided each userâ€™s score_overall and hotel_id.\nusers = pd.read_csv(\"cleaned_users.csv\") #Contained the travelerâ€™s traveller_type (e.g., Couple, Family, Solo).\n\n# ----------------------------------------------------------\n# Q1: Which city is best for each traveler type?\n# ----------------------------------------------------------\nreviews_users = reviews.merge(users[['user_id', 'traveller_type']], on='user_id', how='left')\n#Merged reviews with users using user_id to connect each review with its traveler type.\n\nmerged_df = reviews_users.merge(hotels[['hotel_id', 'city']], on='hotel_id', how='left')\n#Merged the result with hotels using hotel_id to associate each review with the hotelâ€™s city.\n\ncity_ratings = (\n    merged_df.groupby(['traveller_type', 'city'])['score_overall']\n    .mean()\n    .reset_index()\n    .sort_values(by=['traveller_type', 'score_overall'], ascending=[True, False])\n)\n#Grouped by traveller_type and city, and calculated the average overall score (score_overall).\n\nbest_city_per_type = city_ratings.loc[\n    city_ratings.groupby('traveller_type')['score_overall'].idxmax()\n].reset_index(drop=True)\n#Selected the highest-rated city for each traveler type.\n\nprint(\"ðŸ† Best City for Each Traveler Type:\")\ndisplay(best_city_per_type)\n\nplt.figure(figsize=(10, 6))\nsns.barplot(\n    data=best_city_per_type,\n    x='traveller_type',\n    y='score_overall',\n    hue='city',\n    palette='viridis'\n)\nplt.title('Best City per Traveler Type (Average Overall Score)', fontsize=14)\nplt.xlabel('Traveler Type')\nplt.ylabel('Average Score')\nplt.xticks(rotation=30)\nplt.legend(title='City', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.show()\n#Visualized results using a bar plot (traveler type on X-axis, average score on Y-axis, colored by city).","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:35:59.904028Z","iopub.execute_input":"2025-10-24T12:35:59.904364Z","iopub.status.idle":"2025-10-24T12:36:01.592854Z","shell.execute_reply.started":"2025-10-24T12:35:59.904326Z","shell.execute_reply":"2025-10-24T12:36:01.591821Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  2.DATA ENGINEERING QUESTIONS\n##  2.1: What is the best city for each traveler type?\n\nWe aim to determine which city provides the best overall hotel experience for different types of travelers.\n\n### Steps:\n\n1. **Merge Datasets**  \n   - `reviews` merged with `users` on `user_id` to associate each review with the traveler's type.  \n   - Result further merged with `hotels` on `hotel_id` to get the city for each hotel reviewed.\n\n2. **Compute Average Scores**  \n   - Grouped by `traveller_type` and `city` and calculated the **mean `score_overall`**.  \n   - Sorted the results to identify the top-rated cities for each traveler type.\n\n3. **Select Best Cities**  \n   - For each `traveller_type`, selected the city with the **highest average overall score**.\n\n### Findings:\n\n- The resulting table `best_city_per_type` shows the top city for each traveler type.\n- The **bar plot** visually represents the highest-rated city per traveler type, making it easy to compare the average scores.\n\n### Justification:\n\n- This analysis is **hypothesis-driven**: we expect that different traveler types (e.g., Couple, Solo, Family) might prefer different cities due to the types of hotels, activities, or services available.\n- Using **average score** as the metric ensures that the chosen city is consistently rated highly by that traveler type, rather than relying on a single review.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nhotels = pd.read_csv(\"cleaned_hotels.csv\")\nreviews = pd.read_csv(\"cleaned_reviews.csv\")\nusers = pd.read_csv(\"cleaned_users.csv\")\n\n# ----------------------------------------------------------\n# Q2: â€œTop 3 countries with the best value-for-money score per travelerâ€™s age groupâ€\n# ----------------------------------------------------------\n\nmerged = reviews.merge(hotels, on=\"hotel_id\", how=\"left\")\n# Merge reviews with hotels to link each review to a hotel\n\nmerged = merged.merge(users, on=\"user_id\", how=\"left\")\n# Merge users to add traveler demographics\n\n\navg_scores = (\n    merged.groupby([\"age_group\", \"country\"])[\"score_value_for_money\"]\n    .mean()\n    .reset_index()\n)\n# Compute average value-for-money score for each country and age group\n\n\ntop3 = (\n    avg_scores.sort_values([\"age_group\", \"score_value_for_money\"], ascending=[True, False])\n    .groupby(\"age_group\")\n    .head(3)\n)\n# Select top 3 countries for each age group\n\n\nprint(\"Top 3 countries by value-for-money score per age group:\")\nprint(top3)\n\n# Sort for cleaner plotting\ntop3_sorted = top3.sort_values([\"age_group\", \"score_value_for_money\"], ascending=[True, False])\n\n# Set figure size and style\nplt.figure(figsize=(10, 6))\nsns.barplot(\n    data=top3_sorted,\n    x=\"age_group\",\n    y=\"score_value_for_money\",\n    hue=\"country\",\n    palette=\"viridis\"\n)\n#barplot is used to show comparisons clearly between multiple categorical groups.\n\nplt.title(\"Top 3 Countries with Best Value-for-Money Score per Travelerâ€™s Age Group\", fontsize=14)\nplt.xlabel(\"Traveler Age Group\")\nplt.ylabel(\"Average Value-for-Money Score\")\nplt.legend(title=\"Country\", bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:36:01.593916Z","iopub.execute_input":"2025-10-24T12:36:01.594205Z","iopub.status.idle":"2025-10-24T12:36:02.166399Z","shell.execute_reply.started":"2025-10-24T12:36:01.594182Z","shell.execute_reply":"2025-10-24T12:36:02.164907Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.2: Top 3 Countries with Best Value-for-Money Score per Traveler's Age Group\n\nWe aim to identify which countries provide the best value-for-money hotel experience for travelers in different age groups.\n\n#### Steps\n\n**1. Dataset Merging**\n- Merged `reviews` with `hotels` on `hotel_id` to link each review to a hotel\n- Further merged with `users` on `user_id` to include traveler demographics (age_group)\n\n**2. Average Value-for-Money Score Calculation**\n- Grouped data by `age_group` and `country`\n- Calculated mean `score_value_for_money` for each combination to quantify perceived value\n\n**3. Top Country Selection**\n- Sorted grouped results by `score_value_for_money` in descending order\n- Selected top 3 countries for each `age_group`\n\n**4. Results Visualization**\n- Created bar plot with:\n  - X-axis: `age_group`\n  - Y-axis: `score_value_for_money` \n  - Hue: `country` to show top-rated countries per age group\n\n#### Findings\n\n- The `top3` table displays the top three countries with highest value-for-money scores for each age group\n- The bar plot provides clear visual comparison between countries within each age group\n\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nhotels = pd.read_csv(\"cleaned_hotels.csv\")\nreviews = pd.read_csv(\"cleaned_reviews.csv\")\nusers = pd.read_csv(\"cleaned_users.csv\")\n\n\n\ndef map_country_to_group(country):\n    North_America =[   'United States', 'Canada'  ]\n    Western_Europe = [\n           'Germany', 'France', 'United Kingdom',  'Netherlands',\n           'Spain', 'Italy'\n    ]\n    Eastern_Europe =  [ 'Russia' ]\n    East_Asia = ['East_Asia', 'China', 'Japan','South Korea']\n    Southeast_Asia =   ['Thailand' ,'Singapore' ]\n    Middle_East = [ 'United Arab Emirates', 'Turkey' ]\n    Africa = ['Egypt', 'Nigeria', 'South Africa']\n    Oceania = ['Australia' , 'New Zealand']\n    South_America = ['Brazil' , 'Argentina']\n    South_Asia = ['India']\n    North_America_Mexico =['Mexico']\n\n    \n    if country in North_America:\n        return 'North_America'\n    elif country in Western_Europe:\n        return 'Western_Europe'\n    elif country in Eastern_Europe:\n        return 'Eastern_Europe'\n    elif country in East_Asia:\n        return 'East_Asia'\n    elif country in Southeast_Asia:\n        return 'Southeast_Asia'\n    elif country in Middle_East:\n        return 'Middle_East'\n    elif country in Africa:\n        return 'Africa'  \n    elif country in Oceania:\n        return 'Oceania'\n    elif country in South_America:\n        return 'South_America'\n    elif country in South_Asia:\n        return 'South_Asia'\n    elif country in North_America_Mexico:\n        return 'North_America_Mexico'\n    else:\n        return 'Other'\n\n\nif 'country' in merged.columns:\n    merged['country_group'] = merged['country'].map(map_country_to_group)\n    print(\"âœ… 'country_group' column created successfully!\\n\")\n    print(merged.head(2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:36:02.167667Z","iopub.execute_input":"2025-10-24T12:36:02.168009Z","iopub.status.idle":"2025-10-24T12:36:02.409008Z","shell.execute_reply.started":"2025-10-24T12:36:02.167975Z","shell.execute_reply":"2025-10-24T12:36:02.407832Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.PREDICTIVE MODELING \n## 3.1: Mapping Countries to Country Groups\nWe aim to categorize countries into broader geographic groups to reduce complexity and improve interpretability in our analysis and predictive modeling.\n\n### Steps \n\n1. **Define Country Groups**\n\n- Created lists of countries for each group, e.g., North_America, Western_Europe, East_Asia, etc.\n\n- This grouping reflects geographic and cultural similarities that may influence traveler preferences.\n\n2. **Create a Mapping Function**\n\n- map_country_to_group(country) function takes a country name and returns its corresponding group.\n\n- Countries not listed are categorized as Other.\n\n3. **Apply Mapping to Dataset**\n\n- Added a new column 'country_group'  in the merged dataset using the mapping function.\n\n- This column simplifies the prediction task by converting many country labels into 10 meaningful groups.\n\n### Findings \n\n- The first few rows of merged now show the new country_group column.\n\n- Travelers are now categorized into groups such as North_America, Western_Europe, East_Asia, etc., which can be used for multi-class classification in the predictive model.\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.ensemble import RandomForestClassifier\nimport numpy as np\nimport pandas as pd\n\n# Ensure 'country_group' exists\nif 'country_group' not in merged.columns:\n    print(\"âš ï¸ 'country_group' column not found! Please ensure it's created or derived earlier.\")\nelse:\n    # Select relevant features \n    features = ['score_overall', 'value_for_money_base', 'traveller_type', 'age_group', 'user_gender']\n    X = merged[features].copy()\n    y = merged['country_group']\n\n    # Encode categorical variables\n    for col in X.select_dtypes(include='object').columns:\n        X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n\n    y = LabelEncoder().fit_transform(y.astype(str))\n\n    # Scale features\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n\n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n\n    # Train Random Forest model\n    rf_model = RandomForestClassifier(random_state=42)\n    rf_model.fit(X_train, y_train)\n    y_pred = rf_model.predict(X_test)\n\n    # Encode the target variable (country_group)\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(merged['country_group'].astype(str))\n\n    # Display the mapping\n    print(\"\\nðŸ”¢ Country Group Encoding Mapping:\")\n    for i, class_name in enumerate(label_encoder.classes_):\n        print(f\"{i} â†’ {class_name}\")\n\n\n    # Evaluation\n    print(\"\\nðŸ” Random Forest Model Performance:\")\n    print(classification_report(y_test, y_pred))\n\n\n    # Confusion Matrix\n    cm = confusion_matrix(y_test, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot(cmap='Blues')\n    plt.title(\"Confusion Matrix - Country Group Prediction\")\n    plt.show()\n\n\n    # Scatter plot of predicted vs actual (for visualization)\n    plt.figure(figsize=(8, 6))\n    plt.scatter(y_test, y_pred, alpha=0.6)\n    plt.xlabel(\"Actual Country Group\")\n    plt.ylabel(\"Predicted Country Group\")\n    plt.title(\"Actual vs Predicted Country Groups (Scatter Plot)\")\n    plt.show()\n\n\n\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average='weighted')\n    recall = recall_score(y_test, y_pred, average='weighted')\n    f1 = f1_score(y_test, y_pred, average='weighted')\n\n    print(f\"\\nðŸ“Š Model Metrics Summary:\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1-score: {f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:36:02.409954Z","iopub.execute_input":"2025-10-24T12:36:02.410206Z","iopub.status.idle":"2025-10-24T12:36:06.533740Z","shell.execute_reply.started":"2025-10-24T12:36:02.410184Z","shell.execute_reply":"2025-10-24T12:36:06.532469Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.2: Learning Model: Random Forest Classifier\n\n### Objective\nDevelop a predictive model to recommend destination country groups based on traveler preferences, demographics, and review patterns. This enables personalized travel recommendations and targeted marketing strategies.\n\n###  Model Overview\n\n**Algorithm**: Random Forest Classifier  \n**Target Variable**: `country_group` - Categorical classification of destination countries  \n**Features Used**:\n- `score_overall`: Overall satisfaction rating\n- `value_for_money_base`: Perceived value assessment\n- `traveller_type`: Travel type category (Solo, Couple, Family, etc.)\n- `age_group`: Demographic segmentation\n- `user_gender`: Gender information\n\n### ðŸ”§ Data Preprocessing Pipeline\n\n**1. Feature Encoding**\n- Applied Label Encoding to categorical variables (`traveller_type`, `age_group`, `user_gender`)\n- Transformed text categories to numerical representations for model compatibility\n\n**2. Feature Scaling**\n- Standardized all features using `StandardScaler`\n- Ensured equal contribution from all variables regardless of original scale\n- Improved model convergence and performance\n\n**3. Train-Test Split**\n- 80-20 split ratio (Training: 80%, Testing: 20%)\n- Random state fixed for reproducibility\n- Stratified sampling to maintain class distribution\n\n###  Model Training\n\n**Random Forest Classifier Configuration**\n- Ensemble of multiple decision trees\n- Built-in feature importance analysis\n- Robust to overfitting through bagging\n- Handles non-linear relationships effectively\n\n###  Performance Evaluation\n\n**Classification Metrics**:\n- **Accuracy**: Overall correct prediction rate\n- **Precision**: Quality of positive predictions  \n- **Recall**: Coverage of actual positive cases\n- **F1-Score**: Balanced measure of precision and recall\n\n**Visual Diagnostics**:\n- **Confusion Matrix**: Detailed breakdown of prediction vs actual classes\n- **Actual vs Predicted Plot**: Visual alignment check between predictions and ground truth\n\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import Input\n\n\n# Convert labels to categorical one-hot format\nnum_classes = len(np.unique(y))\ny_train_cat = to_categorical(y_train, num_classes)\ny_test_cat = to_categorical(y_test, num_classes)\n\n# Define the improved FFNN\n\nmodel = Sequential([\n    Input(shape=(X_train.shape[1],)),   # âœ… New proper input layer\n    Dense(64, activation='relu'),\n    Dropout(0.3),\n    Dense(32, activation='relu'),\n    Dropout(0.2),\n    Dense(num_classes, activation='softmax')\n])\n\n\n# Compile model\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# ðŸ§© Add Early Stopping to prevent overfitting\nearly_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# Train model (tuned epochs + batch size)\nhistory = model.fit(X_train, y_train_cat,\n                    epochs=50,              # Increased epochs for deeper learning\n                    batch_size=32,          #  Smaller batches help smoother convergence\n                    validation_split=0.2,\n                    callbacks=[early_stop],\n                    verbose=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:36:06.534929Z","iopub.execute_input":"2025-10-24T12:36:06.535306Z","iopub.status.idle":"2025-10-24T12:38:37.617726Z","shell.execute_reply.started":"2025-10-24T12:36:06.535280Z","shell.execute_reply":"2025-10-24T12:38:37.616597Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.3: Learning Model: Feedforward Neural Network (FFNN)\n\n### Model Architecture\n\n**Algorithm**: Deep Feedforward Neural Network (Multi-layer Perceptron)  \n**Problem Type**: Multi-class Classification  \n**Target Variable**: `country_group` (One-hot encoded)  \n**Input Features**: 5 standardized features from preprocessing pipeline\n\n\n**Key Architectural Decisions**:\n\n1. **Input Layer**: Explicit input shape definition for better model stability\n2. **Hidden Layers**: \n   - First hidden layer: 64 neurons with ReLU activation\n   - Second hidden layer: 32 neurons with ReLU activation  \n   - Progressive reduction for feature hierarchy learning\n\n3. **Regularization**:\n   - Dropout (30%) after first hidden layer\n   - Dropout (20%) after second hidden layer\n   - Prevents overfitting and improves generalization\n\n4. **Output Layer**: \n   - Softmax activation for multi-class probability distribution\n   - Number of neurons = unique country groups\n\n### Model Configuration\n\n**Compilation Parameters**:\n- **Optimizer**: Adam (Adaptive Moment Estimation)\n- **Loss Function**: Categorical Crossentropy\n- **Evaluation Metric**: Accuracy\n\n**Training Configuration**:\n- **Epochs**: 50 (with early stopping)\n- **Batch Size**: 32 (balanced convergence speed)\n- **Validation Split**: 20% of training data\n- **Early Stopping**: Monitors val_loss with 5-epoch patience\n\n","metadata":{}},{"cell_type":"code","source":"# Predictions\ny_pred_probs = model.predict(X_test)\ny_pred = np.argmax(y_pred_probs, axis=1)\n\n# Performance report\nprint(\"\\nðŸ”  FFNN Model Performance:\")\nprint(classification_report(y_test, y_pred))\n\n# Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot(cmap='Purples')\nplt.title(\"Confusion Matrix -  FFNN Country Group Prediction\")\nplt.show()\n\n# Key metrics\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred, average='weighted')\nrec = recall_score(y_test, y_pred, average='weighted')\nf1 = f1_score(y_test, y_pred, average='weighted')\n\nprint(f\"ðŸ“Š  FFNN Metrics Summary:\")\nprint(f\"Accuracy: {acc:.4f}\")\nprint(f\"Precision: {prec:.4f}\")\nprint(f\"Recall: {rec:.4f}\")\nprint(f\"F1-score: {f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:38:37.619196Z","iopub.execute_input":"2025-10-24T12:38:37.619952Z","iopub.status.idle":"2025-10-24T12:38:38.838169Z","shell.execute_reply.started":"2025-10-24T12:38:37.619924Z","shell.execute_reply":"2025-10-24T12:38:38.836892Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.3: Learning Model: Feedforward Neural Network (FFNN)\n\n\n### FFNN Model Performance Evaluation\n\n**Prediction Pipeline**:\n1. **Probability Predictions**: Raw softmax outputs for each class\n2. **Class Assignment**: Argmax selection for final predictions\n3. **Comprehensive Evaluation**: Multi-metric performance assessment\n\n### Performance Metrics Analysis\n\n**Classification Report Breakdown**:\n- **Precision**: Measures prediction quality for each class\n- **Recall**: Evaluates coverage of actual class members\n- **F1-Score**: Harmonic mean of precision and recall\n- **Support**: Number of actual occurrences for each class\n\n**Key Performance Indicators**:\n- **Overall Accuracy**: Proportion of correct predictions across all classes\n- **Weighted Metrics**: Account for class imbalance in the dataset\n- **Per-Class Performance**: Detailed analysis of each country group's predictability\n\n### Visual Performance Diagnostics\n\n**Confusion Matrix Insights**:\n- **Diagonal Elements**: Correct predictions (true positives)\n- **Off-Diagonal Elements**: Misclassifications and confusion patterns\n- **Color Intensity**: Visual representation of prediction frequency\n- **Class-wise Performance**: Identification of strong and weak prediction areas\n\n**Pattern Analysis**:\n- Which country groups are frequently confused with each other\n- Systematic misclassification patterns\n- Model strengths and limitations in class discrimination","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Model metrics\nresults = {\n    \"Model\": [\"Random Forest\", \"FFNN\"],\n    \"Accuracy\": [0.6497, 0.6614],\n    \"Precision\": [0.6360, 0.6661],\n    \"Recall\": [0.6497, 0.6614],\n    \"F1-score\": [0.6361, 0.6395]\n}\n\ndf_results = pd.DataFrame(results)\ndisplay(df_results)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:38:38.842098Z","iopub.execute_input":"2025-10-24T12:38:38.842388Z","iopub.status.idle":"2025-10-24T12:38:38.855709Z","shell.execute_reply.started":"2025-10-24T12:38:38.842367Z","shell.execute_reply":"2025-10-24T12:38:38.854582Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot\ndf_results.set_index(\"Model\").plot(kind=\"bar\", figsize=(8,5))\nplt.title(\"Model Performance Comparison: Random Forest vs FFNN\", fontsize=14)\nplt.ylabel(\"Score\")\nplt.ylim(0.6, 0.7)\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\nplt.legend(loc=\"lower right\")\nplt.show()\n\nbest_model = df_results.loc[df_results[\"Accuracy\"].idxmax(), \"Model\"]\nprint(f\"âœ… The better performing model is: {best_model}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:38:38.856721Z","iopub.execute_input":"2025-10-24T12:38:38.856991Z","iopub.status.idle":"2025-10-24T12:38:39.145910Z","shell.execute_reply.started":"2025-10-24T12:38:38.856958Z","shell.execute_reply":"2025-10-24T12:38:39.144594Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.4: Model Performance Comparison: Random Forest vs FFNN\n\n### Executive Summary\n\nAfter comprehensive evaluation of both machine learning approaches, the **Feedforward Neural Network (FFNN)** demonstrates slightly superior performance across key metrics, establishing it as the preferred model for country group prediction.\n\n\n### Key Performance Insights\n\n**FFNN Advantages**:\n- **+1.17%** improvement in Accuracy\n- **+3.01%** improvement in Precision  \n- **+1.17%** improvement in Recall\n- **+0.34%** improvement in F1-Score\n\n**Performance Analysis**:\n- **Accuracy**: FFNN correctly predicts more overall instances\n- **Precision**: FFNN shows better prediction quality (fewer false positives)\n- **Recall**: FFNN captures more true positive cases\n- **F1-Score**: Balanced measure favors FFNN despite smaller margin\n\n### Model Selection Rationale\n\n**Why FFNN Wins**:\n1. **Superior Pattern Recognition**: Better capture of complex feature interactions\n2. **Improved Precision**: Higher confidence in positive predictions\n3. **Consistent Performance**: Balanced across all evaluation metrics\n4. **Scalability Potential**: Better positioned for future data growth\n\n\n### Technical Interpretation\n\n**FFNN Performance Drivers**:\n- Non-linear activation functions capturing complex relationships\n- Dropout regularization preventing overfitting\n- Automatic feature learning through hidden layers\n- Better handling of feature interactions\n\n**Accuracy Context**:\n- Both models significantly outperform random guessing (~20% for 5 classes)\n- 66% accuracy represents meaningful predictive power for travel preferences\n","metadata":{}},{"cell_type":"code","source":"# -------------------------\n# Define encoders (based on training)\n# -------------------------\ntraveller_type_encoder = LabelEncoder().fit(merged['traveller_type'])\nage_group_encoder = LabelEncoder().fit(merged['age_group'])\nuser_gender_encoder = LabelEncoder().fit(merged['user_gender'])\ncountry_group_encoder = LabelEncoder().fit(merged['country_group'])\n\n# -------------------------\n# Inference function\n# -------------------------\ndef predict_country_group(raw_input):\n    \"\"\"\n    Accepts a raw input dictionary with keys:\n    'score_overall', 'value_for_money_base', 'traveller_type', 'age_group', 'user_gender'\n    Returns the predicted country group as a string.\n    \"\"\"\n    # Convert raw input to DataFrame\n    df = pd.DataFrame([raw_input])\n    \n    # Encode categorical features exactly as during training\n    df['traveller_type'] = traveller_type_encoder.transform(df['traveller_type'])\n    df['age_group'] = age_group_encoder.transform(df['age_group'])\n    df['user_gender'] = user_gender_encoder.transform(df['user_gender'])\n    \n    # Select features in the same order as training\n    X = df[['score_overall', 'value_for_money_base', 'traveller_type', 'age_group', 'user_gender']]\n    \n    # Scale features using the same scaler\n    X_scaled = scaler.transform(X)\n    \n    # Predict probabilities using the trained FFNN\n    pred_probs = model.predict(X_scaled)\n    \n    # Get numeric class\n    pred_class_num = np.argmax(pred_probs, axis=1)[0]\n    \n    # Map numeric class to human-readable label\n    return country_group_encoder.inverse_transform([pred_class_num])[0]\n\n# -------------------------\n# Example inputs\n# -------------------------\nexample_1 = {\n    'score_overall': 8.5,\n    'value_for_money_base': 7.8,\n    'traveller_type': 'Couple',\n    'age_group': '25-34',\n    'user_gender': 'Male'\n}\n\nexample_2 = {\n    'score_overall': 6.2,\n    'value_for_money_base': 6.5,\n    'traveller_type': 'Solo',\n    'age_group': '45-54',\n    'user_gender': 'Female'\n}\n\n# -------------------------\n# 4ï¸âƒ£ Run inference\n# -------------------------\nfor i, example in enumerate([example_1, example_2], 1):\n    numeric_pred = np.argmax(model.predict(scaler.transform(\n        pd.DataFrame([{\n            'score_overall': example['score_overall'],\n            'value_for_money_base': example['value_for_money_base'],\n            'traveller_type': traveller_type_encoder.transform([example['traveller_type']])[0],\n            'age_group': age_group_encoder.transform([example['age_group']])[0],\n            'user_gender': user_gender_encoder.transform([example['user_gender']])[0]\n        }]\n    ))), axis=1)[0]\n    \n    label_pred = predict_country_group(example)\n    \n    print(f\"\\nExample #{i}:\")\n    print(\"Raw input:\", example)\n    print(\"Model numeric prediction:\", numeric_pred)\n    print(\"Inference function prediction:\", label_pred)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:38:39.147104Z","iopub.execute_input":"2025-10-24T12:38:39.147721Z","iopub.status.idle":"2025-10-24T12:38:39.632357Z","shell.execute_reply.started":"2025-10-24T12:38:39.147691Z","shell.execute_reply":"2025-10-24T12:38:39.631249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filtered = merged[\n    (merged['score_overall'].between(8.0, 9.0)) & \n    (merged['value_for_money_base'].between(7.5, 8.0)) &\n    (merged['traveller_type'] == 'Couple') &\n    (merged['age_group'] == '25-34') &\n    (merged['user_gender'] == 'Male')\n]\n\nprint(f\"Found {len(filtered)} matching rows.\")\nfiltered.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:38:39.633349Z","iopub.execute_input":"2025-10-24T12:38:39.633719Z","iopub.status.idle":"2025-10-24T12:38:39.677131Z","shell.execute_reply.started":"2025-10-24T12:38:39.633687Z","shell.execute_reply":"2025-10-24T12:38:39.676183Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predicted_group = predict_country_group(example_1)\nprint(\"Predicted Country Group:\", predicted_group)\nprint(\"Actual Country Groups in Filtered Data:\")\nprint(filtered['country_group'].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:38:39.677872Z","iopub.execute_input":"2025-10-24T12:38:39.678125Z","iopub.status.idle":"2025-10-24T12:38:39.801995Z","shell.execute_reply.started":"2025-10-24T12:38:39.678105Z","shell.execute_reply":"2025-10-24T12:38:39.800748Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.5: Inference Function for FFNN Model\n### Objective \nImplement an inference function that takes raw input features for a hotel review and predicts the corresponding country group using the trained FFNN model. This function ensures that predictions are interpretable and consistent with the preprocessing performed during model training.\n\n### Steps:\n\n**1. Define Encoders**\n- LabelEncoder objects were created for all categorical features (`traveller_type`, `age_group`, `user_gender`) and the target variable (`country_group`)\n- These encoders transform categorical text data into numeric labels that the model can process\n- Ensures exact same encoding scheme as training for feature alignment\n\n**2. Inference Function**\n- Accepts a dictionary with raw feature values:\n  - `score_overall`\n  - `value_for_money_base` \n  - `traveller_type`\n  - `age_group`\n  - `user_gender`\n- Converts the input into a DataFrame\n- Applies exact same LabelEncoder transformations as during training\n- Scales the features using the StandardScaler fitted on the training set\n- Feeds the processed input to the FFNN model to obtain class probabilities\n- Returns the predicted country group in natural language, not just numeric labels\n\n**3. Example Demonstration**\n- Two example inputs were tested to verify that the function produces meaningful and interpretable predictions\n- Both the numeric class prediction and the human-readable country group are displayed for transparency\n- Validates end-to-end functionality from raw input to interpretable output","metadata":{}},{"cell_type":"code","source":"pip install shap lime\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:38:39.803031Z","iopub.execute_input":"2025-10-24T12:38:39.803382Z","iopub.status.idle":"2025-10-24T12:38:45.851462Z","shell.execute_reply.started":"2025-10-24T12:38:39.803353Z","shell.execute_reply":"2025-10-24T12:38:45.849936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shap\nimport lime\nfrom lime.lime_tabular import LimeTabularExplainer\nimport numpy as np\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:38:45.853271Z","iopub.execute_input":"2025-10-24T12:38:45.853737Z","iopub.status.idle":"2025-10-24T12:38:54.569024Z","shell.execute_reply.started":"2025-10-24T12:38:45.853686Z","shell.execute_reply":"2025-10-24T12:38:54.567741Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert to numpy if not already\nX_train_np = np.array(X_train)\nX_test_np = np.array(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:38:54.570178Z","iopub.execute_input":"2025-10-24T12:38:54.570516Z","iopub.status.idle":"2025-10-24T12:38:54.576285Z","shell.execute_reply.started":"2025-10-24T12:38:54.570465Z","shell.execute_reply":"2025-10-24T12:38:54.575053Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shap\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# âœ… Wrapper for model predictions\ndef predict_fn(X):\n    return model.predict(X)\n\n# âœ… Convert to NumPy arrays if not already\nX_train_np = np.array(X_train)\nX_test_np = np.array(X_test)\n\n# âœ… Use a small background sample for SHAP (for speed)\nbackground = shap.sample(X_train_np, 50, random_state=42)\n\n# âœ… Create KernelExplainer (compatible with TF 2.16+)\nexplainer = shap.KernelExplainer(predict_fn, background)\n\n# âœ… Compute SHAP values for a small subset (10 test samples for efficiency)\nprint(\"ðŸ” Calculating SHAP values (this may take a few minutes)...\")\nshap_values = explainer.shap_values(X_test_np[:10])\n\n# âœ… Feature names\nfeature_names = list(X.columns)\n\n# âœ… Country group mapping (your encoding)\ncountry_groups = [\n    \"Africa\",\n    \"East_Asia\",\n    \"Eastern_Europe\",\n    \"Middle_East\",\n    \"North_America\",\n    \"North_America_Mexico\",\n    \"Oceania\",\n    \"South_America\",\n    \"South_Asia\",\n    \"Southeast_Asia\",\n    \"Western_Europe\"\n]\n\n# âœ… Loop over each country group (class) and visualize its SHAP values\nfor i, group in enumerate(country_groups):\n    print(f\"\\nðŸ“Š Generating SHAP plots for {group}...\")\n    \n    # Global bar plot (feature importance)\n    plt.title(f\"SHAP Feature Importance - {group}\", fontsize=14)\n    shap.summary_plot(\n        shap_values[i],\n        X_test_np[:10],\n        feature_names=feature_names,\n        plot_type='bar',\n        show=False\n    )\n    plt.show()\n    \n    # Detailed summary (beeswarm-style)\n    plt.title(f\"SHAP Summary Plot - {group}\", fontsize=14)\n    shap.summary_plot(\n        shap_values[i],\n        X_test_np[:10],\n        feature_names=feature_names,\n        show=False\n    )\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T12:38:54.577654Z","iopub.execute_input":"2025-10-24T12:38:54.578333Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. MODEL EXPLAINABILITY  \n## 4.1: Global SHAP Analysis for FFNN \n\n### Objective\nUnderstand and explain the black-box FFNN model by identifying which features most influence destination country group predictions for different traveler segments.\n\n### SHAP Implementation Strategy\n\n**Approach**:\n- **KernelExplainer**: Model-agnostic method compatible with TensorFlow 2.16+\n- **Background Sampling**: 50 samples from training data for reference distribution\n- **Efficient Computation**: Limited to 10 test samples for computational feasibility\n- **Multi-class Analysis**: Separate SHAP values for each country group\n\n","metadata":{}},{"cell_type":"code","source":"import shap\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# âœ… Wrapper for model predictions\ndef predict_fn(X):\n    return model.predict(X)\n\n# âœ… Convert to NumPy arrays if not already\nX_train_np = np.array(X_train)\nX_test_np = np.array(X_test)\n\n# âœ… Use a small background sample for SHAP (for efficiency)\nbackground = shap.sample(X_train_np, 50, random_state=42)\n\n# âœ… Create SHAP KernelExplainer (works with TF 2.16+)\nexplainer = shap.KernelExplainer(predict_fn, background)\n\n# âœ… Compute SHAP values for a small subset\nprint(\"Calculating SHAP values (this may take a few minutes)...\")\nshap_values = explainer.shap_values(X_test_np[:20])  # up to 20 samples for stability\n\n# âœ… Feature names\nfeature_names = list(X.columns)\n\n# âœ… Country group mapping\ncountry_groups = [\n    \"Africa\",\n    \"East_Asia\",\n    \"Eastern_Europe\",\n    \"Middle_East\",\n    \"North_America\",\n    \"North_America_Mexico\",\n    \"Oceania\",\n    \"South_America\",\n    \"South_Asia\",\n    \"Southeast_Asia\",\n    \"Western_Europe\"\n]\n\n# âœ… Combine all SHAP values across all classes\nall_shap_values = np.mean(np.abs(shap_values), axis=0)  # average absolute SHAP values across classes\n\n# âœ… Global summary: Combined Feature Importance\nplt.title(\"Combined SHAP Feature Importance Across All Country Groups\", fontsize=14)\nshap.summary_plot(\n    all_shap_values,\n    X_test_np[:20],\n    feature_names=feature_names,\n    plot_type='bar'\n)\n\n# âœ… Detailed Summary (Combined Beeswarm)\nplt.title(\" Combined SHAP Summary Plot - All Country Groups\", fontsize=14)\nshap.summary_plot(\n    all_shap_values,\n    X_test_np[:20],\n    feature_names=feature_names\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.2: Combined SHAP Analysis for all country groups \n\n### Objective\nProvide a holistic understanding of feature importance across all destination country groups.\n\n### SHAP Methodology\n\n**Approach**:\n- **Expanded Sample Size**: Increased from 10 to 20 test samples for more stable results\n- **Cross-Class Aggregation**: Mean absolute SHAP values across all country groups\n- **Global Perspective**: Combined analysis reveals universal feature importance patterns\n\n","metadata":{}},{"cell_type":"code","source":"# âœ… LOCAL EXPLANATION â€” Force Plot for One Sample\n# Choose one test example\nsample_idx = 0\nsample = X_test_np[sample_idx:sample_idx+1]\npred_class = np.argmax(model.predict(sample))\n\nprint(f\"\\n Local Explanation for Sample #{sample_idx} â†’ Predicted Country Group: {country_groups[pred_class]}\")\n\n# Pick SHAP values for the predicted class\nsample_shap_values = shap_values[pred_class][sample_idx]\n\n# âœ… Get top 5 features by absolute SHAP value\ntop_indices = np.argsort(np.abs(sample_shap_values))[-5:]\ntop_features = [feature_names[i] for i in top_indices]\ntop_shap_values = sample_shap_values[top_indices]\ntop_values = sample[0][top_indices]\n\n# âœ… Visualize only top 5 as force plot\nshap.initjs()\nshap.force_plot(\n    base_value=explainer.expected_value[pred_class],\n    shap_values=top_shap_values,\n    features=top_values,\n    feature_names=top_features,\n    matplotlib=True\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.3: Local SHAP Prediction Explanation \n### Objective\nProvide transparent, instance-level explanation for a specific traveler's destination prediction.\n\n### Approach\n\n**Selected Instance**:\n- **Sample Index**: #0 from test set\n- **Predicted Destination**: `{country_groups[pred_class]}`\n- **Explanation Scope**: Top 5 most influential features\n","metadata":{}},{"cell_type":"code","source":"from lime.lime_tabular import LimeTabularExplainer\nimport numpy as np\n\n# Convert to numpy arrays (as you already did)\nX_train_np = np.array(X_train)\nX_test_np = np.array(X_test)\n\n# âœ… Wrap your model's prediction for LIME\ndef predict_proba_fn(X):\n    preds = model.predict(X)\n    # Convert to class probabilities if needed\n    if preds.ndim == 1:\n        preds = np.column_stack((1 - preds, preds))\n    return preds\n\n# âœ… Initialize the LIME explainer\nexplainer_lime = LimeTabularExplainer(\n    X_train_np,\n    feature_names=list(X.columns),\n    class_names=country_groups,\n    mode='classification'\n)\n\n# âœ… Explain one sample\nsample_idx = 0\nsample = X_test_np[sample_idx]\nexp = explainer_lime.explain_instance(\n    sample,\n    predict_proba_fn,\n    num_features=5\n)\n\n\nexp.show_in_notebook()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.4: LIME Local Interpretable Model Explanations\n### Objective\nProvide alternative, intuitive explanations for individual predictions using locally interpretable surrogate models, complementing SHAP analysis with a different methodological approach.\n\n### Approach\n\n**Core Concept**: \n- Creates simple, interpretable models (like linear regression) that approximate the complex neural network's behavior **locally** around a specific prediction\n- Answers: \"What would a simple model look like if trained only on data similar to this specific instance?\"\n","metadata":{}},{"cell_type":"code","source":"# Get feature names and weights\nfeature_weights = exp.as_list()  # List of tuples: [(feature_name, contribution), ...]\n\n# Separate features and contributions\nfeatures, contributions = zip(*feature_weights)\n\n# Plot manually\nplt.figure(figsize=(8,5))\ncolors = ['green' if c > 0 else 'red' for c in contributions]\nplt.barh(features, contributions, color=colors)\nplt.xlabel(\"Contribution to Prediction\")\nplt.title(f\"LIME Explanation - Sample {sample_idx}\")\nplt.gca().invert_yaxis()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.5: LIME Visualization \n### Visualization Key\n- **Color Coding**: Green for positive contributions, red for negative impacts\n- **Horizontal Layout**: Optimal for feature name readability\n- **Manual Control**: Full customization of styling and formatting\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}